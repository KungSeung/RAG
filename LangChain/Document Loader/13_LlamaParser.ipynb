{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad93d003",
   "metadata": {},
   "source": [
    "LlamaParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4892653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LlamaIndex에서 개발한 문서 파싱 서비스\n",
    "# 대규모 언어 모델(LLM)을 위해 특별히 설계되었다\n",
    "\n",
    "# 주요 특징\n",
    "# PDF, Word, Excel 등 다양한 문서 형식 지원\n",
    "# 자연어 지시를 통한 맞춤형 출력 형식 제공\n",
    "# 복잡한 표와 이미지 추출 기능\n",
    "# JSON 모드 지원\n",
    "# 외국어 지원\n",
    "\n",
    "# LlamaParse는 독립형 API로 제공되며, LlamaCloud 플랫폼의 일부로도 사용 가능합니다. \n",
    "# 이 서비스는 문서를 파싱하고 정제하여 검색 증강 생성(RAG) 등 LLM 기반 애플리케이션의 성능을 향상시키는 것을 목표로 합니다.\n",
    "\n",
    "# 사용자는 무료로 하루 1,000페이지를 처리할 수 있으며, 유료 플랜을 통해 추가 용량을 확보할 수 있습니다. \n",
    "# LlamaParse는 현재 공개 베타 버전으로 제공되고 있으며, 지속적으로 기능이 확장되고 있습니다.\n",
    "\n",
    "import os\n",
    "import nest_asyncio\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# 기본 파서 적용\n",
    "from llama_parse import LlamaParse\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "# 파서 설정\n",
    "parser = Llama_parse(\n",
    "    result_type = \"markdown\",\n",
    "    num_workers = 8,\n",
    "    verbose = True,\n",
    "    language = \"ko\",\n",
    ")\n",
    "\n",
    "# SimpoerDirectoryReader 를 사용하여 파일 파싱\n",
    "file_extractor = {\".pdf\" : parser}\n",
    "\n",
    "documents = SimplerDirectoryReader(\n",
    "    input_files = [\"/SPRI_AI_Brief_2023년12월호_F.pdf\"],\n",
    "    file_extractor = file_extractor,\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10451ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b266c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랭체인 도큐먼트로 변환\n",
    "docs = [doc.to_langchain_format() for doc in documents] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5989003",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff26a1e4",
   "metadata": {},
   "source": [
    "MultiModal Model로 파싱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0c853e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use_vendor_multimodal_model: 멀티모달 모델 사용 여부를 지정합니다. True로 설정하면 외부 벤더의 멀티모달 모델을 사용합니다.\n",
    "# vendor_multimodal_model_name: 사용할 멀티모달 모델의 이름을 지정합니다. 여기서는 \"openai-gpt4o\"를 사용하고 있습니다.\n",
    "# vendor_multimodal_api_key: 멀티모달 모델 API 키를 지정합니다. 환경 변수에서 OpenAI API 키를 가져옵니다.\n",
    "# result_type: 파싱 결과의 형식을 지정합니다. \"markdown\"으로 설정되어 있어 결과가 마크다운 형식으로 반환됩니다.\n",
    "# language: 파싱할 문서의 언어를 지정합니다. \"ko\"로 설정되어 한국어로 처리됩니다.\n",
    "# skip_diagonal_text: 대각선 텍스트를 건너뛸지 여부를 결정합니다.\n",
    "# page_separator: 페이지 구분자를 지정할 수 있습니다.\n",
    "\n",
    "documents = LlamaParse(\n",
    "    use_vendor_multimodal_model = True,\n",
    "    vendor_multimodal_model_name = \"openai-gpt4o\",\n",
    "    vendor_multimodal_api_keys = os.environ[\"OPENAI_API_KEY\"],\n",
    "    result_type = \"markdown\",\n",
    "    language = \"ko\",\n",
    "    # skip_diagonal_text = True,\n",
    "    # page_separator = \"\\n=================\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13843be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing 된 결과\n",
    "parsed_docs = documents.load_data(file_path=\"./SPRI_AI_Brief_2023년12월호_F.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bd23da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain 도큐먼트로 변환\n",
    "docs = [doc.to_langchain_format() for doc in parsed_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442a288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing instruction 을 지정합니다.\n",
    "parsing_instruction = (\n",
    "    \"You are parsing a brief of AI Report. Please extract tables in markdown format.\"\n",
    ")\n",
    "\n",
    "# LlamaParse 설정\n",
    "parser = LlamaParse(\n",
    "    use_vendor_multimodal_model=True,\n",
    "    vendor_multimodal_model_name=\"openai-gpt4o\",\n",
    "    vendor_multimodal_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    result_type=\"markdown\",\n",
    "    language=\"ko\",\n",
    "    parsing_instruction=parsing_instruction,\n",
    ")\n",
    "\n",
    "# parsing 된 결과\n",
    "parsed_docs = parser.load_data(file_path=\"data/SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
    "\n",
    "# langchain 도큐먼트로 변환\n",
    "docs = [doc.to_langchain_format() for doc in parsed_docs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989056a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# markdown 형식으로 추출된 테이블 확인\n",
    "print(docs[-2].page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
